[requests_headers]
# Mask every request with this user-agent.
# user-agent = Mozilla/5.0 (Windows NT 6.3; WOW64; rv:38.0) Gecko/20100101 Firefox/38.0

[general]
# db_engine to use. mysql or postgresql are possible.
db_engine = postgresql
# When walking folders, only add as new files the ones that fit this filter.
# Why change this if this program only works with ZIP compressed files? to look for CBZ or other ZIP compressed files.
filename_filter = *.zip
# Django secret key, needed. CHANGE IT. Don't use % here.
django_secret_key = 89!yi9gvd2r*m5rq9y-elj86u*zg@-j3ce90@^7+0(-!fkgpzd
# Enable Django debug mode, that will be more verbose in case of something going wrong.
django_debug_mode = yes
# API key, that will be applied to the JSON server, JSON view, and userscript. MUST CHANGE.
api_key = panda_backup
# How torrent downloads are handled. remote means file is downloaded on a remote server, so the file must be downloaded via FTP from that server.
# local_copy, local_move, local_hardlink means files will be copied or moved instead of FTP downloading.
# For hardlinks, make sure that it's being copied under the same filesystem.
download_handler = local_copy
# Wait timer used for most request. A value that should not get you banned is 6 seconds. Lower than that is risky.
wait_timer = 6
# Start the timed downloader on startup.
timed_downloader_startup = no
# Timed downloader cycle timer.
timed_downloader_cycle_timer = 5
# Number of parallel post downloaders (each one opens a FTP connection).
parallel_post_downloaders = 4
# Reload the server when it detects file changes (CherryPy feature).
cherrypy_auto_restart = yes
# Auto discard galleries that contain these tags. For new downloads and matches.
banned_tags = language:thai,language:chinese,language:korean,language:french,language:spanish,language:italian,language:hungarian,language:portuguese,language:polish,language:russian,language:vietnamese
banned_uploaders =
# WARNING: will add all galleries as public, not only feed ones.
add_as_public = no

# each provider specific settings must be prepended with a "provider_" string.
[panda_general]
# When crawling the home pages, stop at limit page number. This parameter is optional
stop_page_number = 5
# panda RSS reports categories, you can use this to pre-filter what galleries can be processsed, check panda.settings for possible options.
accepted_rss_categories = [Doujinshi],[Manga],[Artist CG Sets],[Game CG Sets],[Image Sets],[Non-H],[Cosplay],[Asian Porn],[Misc],[Private]

[panda_locations]
# Relative location where hath downloads will be stored.
hath_dl_folder = galleries/hath_dls
# Local path were the hath downloads are stored (in case a local folder is being used).
local_hath_folder = /home/panda/hh/download
# Where the hath downloads are located on the remote server.
remote_hath_dir = /hh/download

[panda_cookies]
# Log into exhentai on your browser, check all the cookies for it, and paste their keys, values here.
# uconfig one is necessary if you want filters on every request.
# Also archive download must be set to autodownload, autoaccept.
ipb_member_id =
ipb_pass_hash =
yay =
uconfig =

[nhentai_cookies]
# Session cookie for nhentai. Enables torrent downloads.
# sessionid =

[fakku_cookies]
# Session cookie for FAKKU. Enables fetching "controversial" galleries metadata.
# fakku_sid =

[mugimugi_general]
# mugimugi api key
api_key =

[cafe_locations]
# Relative location where archive downloads will be stored.
archive_dl_folder = galleries/rips/cafe

[monitored_links]
# Control the startup of the monitored_links subsystem (threads)
enable = no

[downloaders]
# List of possible downloaders to use. Negative values disable that particular downloader.
# Positive values are sorted ascending in their use, so if the first one fails, the next one will try to download.
# Warning: Some of them might be outdated.
panda_archive = 4
panda_torrent = 3
panda_hath = -1
panda_info = -1
nhentai_torrent = -1
fakku_info = 1
mugimugi_info = 1

[autochecker]
# Gallery autodownloader, if page provided finds filters based on title and tags.
# To download all galleries from a certain provider, create a WantedGallery that has no filter, and set it's provider.
enable = no
startup = no
cycle_timer = 2
# Providers to check from, they must have implemented a crawl_feed method (panda,cafe).
providers = panda

[autoupdater]
# Auto update gallery metadata (only panda is supported).
enable = no
startup = no
cycle_timer = 2
# How many days back for filtering galleries to update
buffer_back = 3
# How many days after for filtering galleries to update
buffer_after = 0
# Which providers use the autoupdater.
providers = panda

[auto_wanted]
# Auto add entries as wanted galleries from providers based on filters.
enable = no
startup = no
cycle_timer = 4
# Automatically add this text to "unwanted_title" field on generated wanted galleries
unwanted_title = [Rewrite]

[pushover]
# Pushover notifications on wanted galleries found.
enable = no
# Required:
user_key =
token =
# Optional:
device =
sound =

[allowed]
# If set to yes, galleries marked as failed that are added again to download will be processed.
retry_failed = no
# If set to yes, galleries that were already added will be processed if added again.
replace_metadata = no
# If set to yes, galleries that were already added and downloaded will be redownloaded.
# WARNING: if you use autocheckers, it will keep redownloading files. This is mostly used internally.
redownload = no
# If set to yes, torrent downloads using the .rar format will be automatically transformed to .zip file. Requires the rarfile module.
convert_rar_to_zip = yes
# After finding a non-match, try to match with internal galleries right away.
internal_matches_for_non_matches = no

[matchers]
# List of possible matchers to use. Negative values disable that particular matcher.
# Positive values are sorted ascending in their use, so if the first one fails, the next one will try to match.
# Warning: some of them might be outdated.
panda_title = 2
panda_cover = 1
panda_image = -1
google_title = 3
nhentai_title = 4
fakku_title = -1

[match_params]
# If set to yes, archives already matched that fit into "rematch_file_list" will be matched again.
rematch_file = no
# List of match_types that will be considered in a rematch.
rematch_file_list = non-match
# Rehash files for their CRC32.
rehash_files = no
# If an archive with the same CRC32 is found, copy its matching info.
copy_match_file = yes

[locations]
# Absolute location in the filesystem where the media will be stored. Includes archives, thumbnails, and extracted archives.
media_root =
# Relative location where archive (HTTP) downloads will be stored. Can be replaced by each provider.
archive_dl_folder = galleries/archive_dls
# Relative location where torrent downloads will be stored. Can be replaced by each provider.
torrent_dl_folder = galleries/torrent_dls
# Custom absolute location for the logfile. Can be commented to use the default folder.
# log_location = /home/panda/crawler.log

[urls]
# URLs for webserver
media_url = /media/
static_url = /static/
viewer_main_url =
# If it's being served behind a reverse proxy, activate this option to fix absolute URL generation.
behind_proxy = no
# Enable the /submit URL for any user (even non-registered) to submit possible panda links to add.
enable_public_submit = no
# Enable public facing stats
enable_public_stats = no
# User facing URL, (scheme+authority), used to resolve absolute URLs were the request is not accesible.
main_webserver_url =

[database]
# If mysql is the db_engine these parameters must be filled.
mysql_name = pandafrontend
mysql_user = pandaadmin
mysql_password = pandaadmin
mysql_host = localhost
mysql_port = 3306
# If postgresql is the db_engine, these parameters must be filled.
postgresql_name = pandaweb
postgresql_user = pandaadmin
postgresql_password = pandaadmin
postgresql_host = localhost
postgresql_port = 5432

[torrent]
# Parameters needed if using a torrent downloader to configure the connection to the torrent client. Possible clients: Transmission, uTorrent.
client = transmission
user = panda
pass = panda
address = http://localhost/transmission/rpc
port = 9091
# download_dir only implemented for transmission
download_dir = /home/panda/downloads/torrents
# By default, the vality of the server certificate is checked. If it's a self-signed cert for example, set it to "yes".
# no_certificate_check = yes

[ftps]
# Download files from the remote server, when using remote handler. Only option available is FTPS connection.
address = remote.server.com
user = panda
passwd = panda
# Where the torrent downloads are located on the remote server.
remote_torrent_dir = /home/pandaremote/downloads/torrent
# If specified, address binded to when opening FTP connections to the remote server.
# bind_address =
# By default, the vality of the server certificate is checked. If it's a self-signed cert for example, set it to "yes".
# no_certificate_check = yes

[webserver]
# Webserver information, if used.
bind_address = 0.0.0.0
bind_port = 8090
# Only needed if enable_ssl is yes.
# ssl_certificate = /home/panda/certs/panda.crt
# Only needed if enable_ssl is yes.
# ssl_private_key = /home/panda/certs/panda.key
# Enable SSL for all transmissions from the webserver.
enable_ssl = no
# Write access log to file.
write_access_log = no
# Log to screen.
log_to_screen = yes

[remote_site]
# Used if two instances of this application are running, to communicate between them
api_url = https://panda.chaika.moe/jsonapi
api_key = asdf1234
remote_folder = /media/galleries/archives

[mail_logging]
# Some stuff will be reported to email. (Server Error, new gallery submissions.)
enable = no
mailhost =
from =
to =
subject =
username =
password =

# Elastic seach for advanced search
[elasticsearch]
enable = no
url = http://localhost:9200/
max_result_window = 10000
auto_refresh = no
index_name = viewer